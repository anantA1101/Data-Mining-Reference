{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JnqS7R24nirp"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0aa0b027fcb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When developing algorithms it is often desirable to have datasets for testing purposes. When there is no access to a suitable dataset, sometimes it is convenient to generate synthetic data. In this tutorial, we will  \n",
    "1. create synthetic datasets consisting of two classes of objects;\n",
    "2. develop the k-NN algorithm;\n",
    "3. evaluate the algorithm's ability to separate the two classes of objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1. Create synthetic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to generate training and validation datasets for binary classification. For visualisation purposes, we will assume that our objects have 2 numeric features. We would like to generate 2 \"cloulds\" of points on the plane corresponding to the positive and negative objects respectively. To do this, one can generate random points from a [multivariate normal distribution](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) (function $\\texttt{np.random.multivariate_normal}$). For example, $\\texttt{np.random.multivariate_normal([a,b], [[1,0],[0,1]], N)}$ will generate a set on N points scattered around the *mean* point $(a,b)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create two sets of $N=10$ points. The first set scattered around the point $(0,0)$ and the second scattered around the point $(2,2)$. These sets of points will correspond to the positive and the negative class respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = np.random.multivariate_normal([0,0], [[1,0],[0,1]], N)\n",
    "negative = np.random.multivariate_normal([2,2], [[1,0],[0,1]], N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Plot the generated sets of points. Use different colours or markers for different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(positive[:,0], positive[:,1], c='b')\n",
    "plt.scatter(negative[:,0], negative[:,1], c='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split each of the sets into equal train and validation portions. As a result you should have four sets: \n",
    "- positive object in the train dataset;\n",
    "- positive object in the validation dataset;\n",
    "- negataive object in the train dataset;\n",
    "- negataive object in the validation dataset;\n",
    "\n",
    "To confirm that the sets have equal numbers of objects, print the number of elements in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4M8bjuyfnisE"
   },
   "outputs": [],
   "source": [
    "halfN = int(N/2)\n",
    "train_positive = positive[:halfN,:]\n",
    "validation_positive = positive[halfN:,:]\n",
    "\n",
    "train_negative = negative[:halfN,:]\n",
    "validation_negative = negative[:halfN,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iur5EAO5nisJ",
    "outputId": "4ccd1457-5819-4102-9233-4537408f3365"
   },
   "outputs": [],
   "source": [
    "print(len(train_positive), len(validation_positive), len(train_negative), len(validation_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Add an extra freature (representing the class label: +1 for the positive class, -1 for the negative class) to the train and validation instances. As a result you will have two datasets, each consisting of tuples (label, instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCYl3vQWnisS"
   },
   "outputs": [],
   "source": [
    "train_data = [(1, x) for x in train_positive]\n",
    "train_data.extend([(-1, x) for x in train_negative])\n",
    "\n",
    "validation_data = [(1, x) for x in validation_positive]\n",
    "validation_data.extend([(-1, x) for x in validation_negative])\n",
    "\n",
    "# To see that we have properly made tuples of (label, instance) lets print train and validation data.\n",
    "print(\"Train data:\\n\", train_data)\n",
    "print(\"\\nValidation data:\\n\", validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 2. Develop the k-NN algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement k-NN prediction function that uses the training dataset from the previous exercise. Use cosine similarity as a \"measure of distance\". The larger the similarity between two objects, the closer the objects are to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wECY1E1jnisj"
   },
   "source": [
    "1. Create the cosine similarity function that will be used in the k-NN prediction function to find the neighbours. The function should take two vectors as input and output the cosine similarity between the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6VfNVJTniso"
   },
   "outputs": [],
   "source": [
    "def cosSimilarity(p, q):\n",
    "    score = np.dot(p,q) / (np.linalg.norm(p) * np.linalg.norm(q))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D15_YJKXnist"
   },
   "source": [
    "2. Implement a function that predicts the class of a validation instance using the k-NN algorithm. The function should take a validation instance and the parameter $k$ as input, and output predicted class of the validation instance (+1 or -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKh9Ze2Znisw"
   },
   "outputs": [],
   "source": [
    "def predict(x, k):\n",
    "    # The first thing we do is computing the similarity scores between x and each instance z in our train dataset. \n",
    "    # We must also store the labels so that we can later find the majority label.\n",
    "    L = [(y, cosSimilarity(x, z)) for (y,z) in train_data]\n",
    "    \n",
    "    # Next, we need to find the neighbours. \n",
    "    # For that we sort this list of tuples by the value of the second item in tuples, which is similarity.\n",
    "    #\n",
    "    # We use lambda expressions, which are convenient for writing in-place functions. \n",
    "    # Here, we take an element from our list and return its similarity component, \n",
    "    # which is used by the sort function to compare two elements. \n",
    "    # \"reverse=True\" ensures that sorting is done in the descending order of similarity.\n",
    "    L.sort(key=lambda a: a[1], reverse=True)\n",
    "    \n",
    "    # If you would like to confirm that it is indeed the descending order you can print the list after sorting (uncomment the line below).\n",
    "    #print(L[:k])\n",
    "    \n",
    "    # Next, we must find the majority label. \n",
    "    # Since we are doing binary classification and our labels are -1 and +1, \n",
    "    # when we add the labels for the nearest neigbours if we get a positive value then there must be more +1s than -1s, and vice versa. \n",
    "    # You might have to do more complicated stuff for finding the majority label if there were more than 2 classes. \n",
    "    # But it is easy for the binary case as shown here.\n",
    "    score = sum([e[0] for e in L[:k]])\n",
    "    if score > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 3. Evaluate the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement $\\texttt{kNNaccuracy}$ function that takes the parameter $k$ and the validation dataset as input and output the accuracy of the k-NN algorithm on the validation dataset. Use the function to compute the accuracy of prediciton of the k-NN classifier on the validation dataset, when $k = 5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40dffWDgnitG",
    "outputId": "bf066a61-1bed-4840-c595-5e9effe3437e"
   },
   "outputs": [],
   "source": [
    "def kNNaccuracy(k, validation_data):\n",
    "    correctPredictions = 0\n",
    "    for (y,x) in validation_data:\n",
    "        if y == predict(x, k):\n",
    "            correctPredictions += 1\n",
    "    accuracy = float(correctPredictions) / float(len(validation_data))\n",
    "    return accuracy\n",
    "\n",
    "print(\"Accuracy of 5-NN: \", kNNaccuracy(5, validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Generate new datasets with $N=100$. Compute accuracies of k-NN for all odd $k$ from 1 to 99. Plot k-NN accuracy versus $k$. What is the best value of $k$ for the validation dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kRange = range(1,100,2)\n",
    "# Compute accuracies\n",
    "accuracyValues = [kNNaccuracy(i, validation_data) for i in kRange]\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(kRange, accuracyValues, 'b')\n",
    "plt.xlabel(\"Parameter k\")\n",
    "plt.ylabel(\"Accuracy of k-NN\")\n",
    "plt.title(\"k-NN accuracy versus k\")\n",
    "plt.show()\n",
    "\n",
    "# Find the best k for the current validation dataset\n",
    "print(\"Best k: \", kRange[np.argmax(accuracyValues)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWoB_tlonitK"
   },
   "source": [
    "3. Conduct further experiments:\n",
    "    * change the value of $k$\n",
    "    * increase the number of instances $N$ (make sure that $N$ is even)\n",
    "    * separate or bring together the two classes by adjusting the means of the two Gaussians.\n",
    "\n",
    "How does the accuracy vary in each case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "k-NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
